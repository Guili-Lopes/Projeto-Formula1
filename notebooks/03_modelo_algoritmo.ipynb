{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Plackett–Luce Bayesiano Hierárquico e o Algoritmo Power EP\n",
    "\n",
    "## Modelo Plackett–Luce\n",
    "O modelo Plackett–Luce é amplamente utilizado para trabalhar com dados de ranking. Ele associa a cada item (como um piloto de Fórmula 1) um parâmetro positivo de “habilidade”. A probabilidade de observar uma ordem (ranking) é calculada considerando a chance de cada item ser escolhido em cada posição, proporcional à sua habilidade relativa. Assim, quanto maior o parâmetro de um piloto, maior a probabilidade de ele aparecer nas primeiras posições.\n",
    "\n",
    "Na versão Bayesiana, esses parâmetros não são fixos, mas tratados como variáveis aleatórias com distribuições a priori (por exemplo, distribuições Gama ou Normais no logaritmo da habilidade). Isso permite incorporar incerteza e obter distribuições a posteriori que descrevem não apenas estimativas pontuais das habilidades, mas também intervalos de confiança sobre elas. Essa abordagem é poderosa para contextos como esportes, onde o desempenho pode variar ao longo do tempo ou entre contextos.\n",
    "\n",
    "## Inferência Bayesiana\n",
    "A inferência Bayesiana busca calcular a distribuição a posteriori dos parâmetros dado os dados observados. Na prática, isso geralmente é feito via métodos de amostragem como MCMC (Markov Chain Monte Carlo). O resultado é uma visão probabilística das habilidades estimadas, com medidas de incerteza que permitem análises mais ricas do que simples estimativas determinísticas.\n",
    "\n",
    "## Algoritmo Power EP\n",
    "O algoritmo Expectation Propagation (EP) é uma técnica de aproximação para inferência Bayesiana. Ele funciona ao aproximar fatores complicados da distribuição a posteriori por distribuições mais simples, atualizando essas aproximações de forma iterativa. O Power EP é uma extensão desse método: em vez de usar a divergência de Kullback–Leibler padrão, ele utiliza uma família de divergências chamada α-divergence. Isso introduz um parâmetro extra (α) que controla o equilíbrio entre viés e variância da aproximação.\n",
    "\n",
    "Na prática, o Power EP é útil quando o MCMC é caro ou inviável, pois oferece aproximações mais rápidas para distribuições complexas. Em modelos como o Plackett–Luce com muitos itens (pilotos, por exemplo), o Power EP pode fornecer inferência eficiente e escalável, ainda que aproximada.\n",
    "\n",
    "## Conclusão\n",
    "- O modelo Plackett–Luce descreve rankings completos com base em parâmetros de habilidade.\n",
    "- A abordagem Bayesiana adiciona priors e gera distribuições a posteriori, permitindo quantificar incerteza.\n",
    "- MCMC fornece resultados robustos, mas pode ser computacionalmente caro.\n",
    "- O Power EP surge como uma alternativa aproximada mais rápida, útil em cenários de grande escala e quando o custo da inferência exata é proibitivo.\n"
   ],
   "id": "83eeec076fe49d45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
